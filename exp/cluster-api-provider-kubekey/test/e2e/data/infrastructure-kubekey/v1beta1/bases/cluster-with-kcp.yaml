---
# KKCluster object referenced by the Cluster object
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: KKCluster
metadata:
  name: '${CLUSTER_NAME}'
spec:
  component:
    zone: '${KKZONE}'
  nodes:
    auth:
      user: '${USER_NAME}'
      password: '${PASSWORD}'
    instances: '${INSTANCES}'
  controlPlaneLoadBalancer:
    host: '${CONTROL_PLANE_ENDPOINT_IP}'
---
# Cluster object with
# - Reference to the KubeadmControlPlane object
# - the label cni=${CLUSTER_NAME}-crs-0, so the cluster can be selected by the ClusterResourceSet.
apiVersion: cluster.x-k8s.io/v1beta1
kind: Cluster
metadata:
  name: '${CLUSTER_NAME}'
  labels:
    cni: "${CLUSTER_NAME}-crs-0"
spec:
  clusterNetwork:
    services:
      cidrBlocks: ['${SERVICE_CIDRS}']
    pods:
      cidrBlocks: ['${POD_CIDRS}']
    serviceDomain: '${SERVICE_DOMAIN}'
  infrastructureRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
    kind: KKCluster
    name: '${CLUSTER_NAME}'
  controlPlaneRef:
    kind: KubeadmControlPlane
    apiVersion: controlplane.cluster.x-k8s.io/v1beta1
    name: "${CLUSTER_NAME}-control-plane"
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: KKMachineTemplate
metadata:
  name: "${CLUSTER_NAME}-control-plane"
spec:
  template:
    spec:
      roles:
        - control-plane
---
# KubeadmControlPlane referenced by the Cluster object with
# - the label kcp-adoption.step2, because it should be created in the second step of the kcp-adoption test.
kind: KubeadmControlPlane
apiVersion: controlplane.cluster.x-k8s.io/v1beta1
metadata:
  name: "${CLUSTER_NAME}-control-plane"
  labels:
    kcp-adoption.step2: ""
spec:
  replicas: ${CONTROL_PLANE_MACHINE_COUNT}
  machineTemplate:
    infrastructureRef:
      kind: KKMachineTemplate
      apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
      name: "${CLUSTER_NAME}-control-plane"
  kubeadmConfigSpec:
    clusterConfiguration:
      controllerManager:
        extraArgs: {enable-hostpath-provisioner: 'true'}
      apiServer:
        # host.docker.internal is required by kubetest when running on macOS because of the way ports are proxied.
        certSANs: [localhost, 127.0.0.1, 0.0.0.0, host.docker.internal]
    files:
      - content: |
          apiVersion: v1
          kind: Pod
          metadata:
            creationTimestamp: null
            name: kube-vip
            namespace: kube-system
          spec:
            containers:
            - args:
              - manager
              env:
              - name: address
                value: ${CONTROL_PLANE_ENDPOINT_IP}
              - name: vip_interface
                value: ${VIP_NETWORK_INTERFACE=""}
              - name: vip_arp
                value: "true"
              - name: port
                value: "6443"
              - name: vip_cidr
                value: "32"
              - name: cp_enable
                value: "true"
              - name: cp_namespace
                value: kube-system
              - name: vip_ddns
                value: "false"
              - name: svc_enable
                value: "true"
              - name: vip_leaderelection
                value: "true"
              - name: vip_leaseduration
                value: "5"
              - name: vip_renewdeadline
                value: "3"
              - name: vip_retryperiod
                value: "1"
              - name: lb_enable
                value: "true"
              - name: lb_port
                value: "6443"
              image: ghcr.io/kube-vip/kube-vip:v0.5.0
              imagePullPolicy: IfNotPresent
              name: kube-vip
              resources: {}
              securityContext:
                capabilities:
                  add:
                  - NET_ADMIN
                  - NET_RAW
              volumeMounts:
              - mountPath: /etc/kubernetes/admin.conf
                name: kubeconfig
            hostNetwork: true
            hostAliases:
              - hostnames:
                  - kubernetes
                ip: 127.0.0.1
            volumes:
            - hostPath:
                path: /etc/kubernetes/admin.conf
                type: FileOrCreate
              name: kubeconfig
          status: {}
        owner: root:root
        path: /etc/kubernetes/manifests/kube-vip.yaml
    initConfiguration:
      nodeRegistration:
        criSocket: unix:///var/run/containerd/containerd.sock
        kubeletExtraArgs:
          eviction-hard: 'nodefs.available<0%,nodefs.inodesFree<0%,imagefs.available<0%'
    joinConfiguration:
      nodeRegistration:
        criSocket: unix:///var/run/containerd/containerd.sock
        kubeletExtraArgs:
          eviction-hard: 'nodefs.available<0%,nodefs.inodesFree<0%,imagefs.available<0%'
  version: "${KUBERNETES_VERSION}"
